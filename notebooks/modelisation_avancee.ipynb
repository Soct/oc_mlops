{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b5f280",
   "metadata": {},
   "source": [
    "# üöÄ Mod√©lisation Avanc√©e - Home Credit Default Risk\n",
    "\n",
    "Ce notebook explore des mod√®les avanc√©s avec optimisation d'hyperparam√®tres via **Optuna** :\n",
    "- **XGBoost** : Gradient Boosting optimis√©\n",
    "- **LightGBM** : Gradient Boosting ultra-rapide\n",
    "- **MLP** : Multi-Layer Perceptron (r√©seau de neurones)\n",
    "\n",
    "## Strat√©gie\n",
    "\n",
    "1. **Pipelines flexibles** : Preprocessing + mod√®le\n",
    "2. **Optimisation Optuna** : Recherche bay√©sienne d'hyperparam√®tres\n",
    "3. **Tracking MLflow** : Versionnement et comparaison\n",
    "4. **M√©trique m√©tier** : Co√ªt FN = 10x FP\n",
    "5. **Validation crois√©e** : StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cebd6",
   "metadata": {},
   "source": [
    "## üì¶ Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e83b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports r√©ussis\n",
      "üì¶ Versions:\n",
      "   - XGBoost:  3.2.0\n",
      "   - LightGBM: 4.6.0\n",
      "   - Optuna:   4.7.0\n",
      "   - MLflow:   2.22.4\n"
     ]
    }
   ],
   "source": [
    "# Imports standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, recall_score, f1_score, \n",
    "    make_scorer, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Mod√®les\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Optimisation & Tracking\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")\n",
    "print(f\"üì¶ Versions:\")\n",
    "print(f\"   - XGBoost:  {xgb.__version__}\")\n",
    "print(f\"   - LightGBM: {lgb.__version__}\")\n",
    "print(f\"   - Optuna:   {optuna.__version__}\")\n",
    "print(f\"   - MLflow:   {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af80e1a",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da640560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es:\n",
      "   Train : (307507, 795) (307,507 √©chantillons)\n",
      "   Test  : (48744, 795)\n",
      "\n",
      "üìä Distribution des classes:\n",
      "   Classe 0: 282,682 (91.9%)\n",
      "   Classe 1: 24,825 (8.1%)\n",
      "   Ratio: 1:11.4\n"
     ]
    }
   ],
   "source": [
    "# Charger les features engineered\n",
    "df = pd.read_parquet('../data/features_engineered.parquet')\n",
    "\n",
    "# S√©parer train et test\n",
    "train = df[df['TARGET'].notna()].copy()\n",
    "test = df[df['TARGET'].isna()].copy()\n",
    "\n",
    "# Pr√©parer pour l'entra√Ænement\n",
    "X_train = train.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "y_train = train['TARGET']\n",
    "\n",
    "# Pour les pr√©dictions finales\n",
    "X_test = test.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "test_ids = test['SK_ID_CURR']\n",
    "\n",
    "print(f\"‚úÖ Donn√©es charg√©es:\")\n",
    "print(f\"   Train : {X_train.shape} ({len(y_train):,} √©chantillons)\")\n",
    "print(f\"   Test  : {X_test.shape}\")\n",
    "print(f\"\\nüìä Distribution des classes:\")\n",
    "print(f\"   Classe 0: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Classe 1: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.1f}%)\")\n",
    "print(f\"   Ratio: 1:{(y_train == 0).sum() / (y_train == 1).sum():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeb1a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Nettoyage des donn√©es...\n",
      "‚úÖ Donn√©es nettoy√©es: (307507, 795)\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des valeurs probl√©matiques\n",
    "print(\"üßπ Nettoyage des donn√©es...\")\n",
    "\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"‚úÖ Donn√©es nettoy√©es: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab299f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset: (246005, 795)\n",
      "Val subset:   (61502, 795)\n"
     ]
    }
   ],
   "source": [
    "# Train/Val split pour le test rapide\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    stratify=y_train, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train subset: {X_tr.shape}\")\n",
    "print(f\"Val subset:   {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9942892",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae16cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MLflow Tracking URI: file:///home/zmxw1768/Documents/oc_mlops/mlruns\n",
      "üìÅ Stockage: /home/zmxw1768/Documents/oc_mlops/mlruns\n",
      "üß™ Exp√©rience: Advanced Models - Optuna Optimization\n",
      "‚úÖ MLflow configur√©\n"
     ]
    }
   ],
   "source": [
    "# Configuration MLflow en local\n",
    "tracking_uri = os.path.abspath(os.path.join(os.getcwd(), '..', 'mlruns'))\n",
    "mlflow.set_tracking_uri(f\"file://{tracking_uri}\")\n",
    "mlflow.set_experiment(\"Advanced Models - Optuna Optimization\")\n",
    "\n",
    "print(f\"üéØ MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"üìÅ Stockage: {tracking_uri}\")\n",
    "print(f\"üß™ Exp√©rience: Advanced Models - Optuna Optimization\")\n",
    "\n",
    "# Fermer toute run active\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "    \n",
    "print(\"‚úÖ MLflow configur√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56413a",
   "metadata": {},
   "source": [
    "## üìê M√©triques Personnalis√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75781381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√©triques configur√©es:\n",
      "   - ROC-AUC\n",
      "   - Recall (classe minoritaire)\n",
      "   - F1-Score\n",
      "   - Co√ªt m√©tier (FN=10x FP)\n"
     ]
    }
   ],
   "source": [
    "def business_cost_scorer(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Co√ªt m√©tier : FN (faux n√©gatif) co√ªte 10 fois plus cher que FP (faux positif)\n",
    "    On retourne le n√©gatif du co√ªt pour maximiser (sklearn maximise les scores)\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = fp * 1 + fn * 10  # FN co√ªte 10x plus\n",
    "    return -cost  # N√©gatif car on veut minimiser le co√ªt\n",
    "\n",
    "# Configuration de la validation crois√©e\n",
    "N_SPLITS = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# D√©finir les scorers\n",
    "scoring = {\n",
    "    'roc_auc': make_scorer(roc_auc_score, response_method='predict_proba'),\n",
    "    'recall_minority': make_scorer(recall_score, pos_label=1, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, pos_label=1, zero_division=0),\n",
    "    'business_cost': make_scorer(business_cost_scorer)\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ M√©triques configur√©es:\")\n",
    "print(f\"   - ROC-AUC\")\n",
    "print(f\"   - Recall (classe minoritaire)\")\n",
    "print(f\"   - F1-Score\")\n",
    "print(f\"   - Co√ªt m√©tier (FN=10x FP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e024be",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Pipelines pour chaque mod√®le\n",
    "\n",
    "Chaque pipeline inclut :\n",
    "1. **Scaler** : Normalisation des features\n",
    "2. **Classifier** : Mod√®le de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef52fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de cr√©ation de pipelines d√©finies:\n",
      "   - create_xgboost_pipeline()\n",
      "   - create_lightgbm_pipeline()\n",
      "   - create_mlp_pipeline()\n"
     ]
    }
   ],
   "source": [
    "def create_xgboost_pipeline(params=None):\n",
    "    \"\"\"\n",
    "    Pipeline XGBoost avec preprocessing\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionnaire d'hyperparam√®tres (optionnel)\n",
    "    \"\"\"\n",
    "    default_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 1,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    \n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    # Calcul de scale_pos_weight pour g√©rer le d√©s√©quilibre\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    default_params['scale_pos_weight'] = scale_pos_weight\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', xgb.XGBClassifier(**default_params))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def create_lightgbm_pipeline(params=None):\n",
    "    \"\"\"\n",
    "    Pipeline LightGBM avec preprocessing\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionnaire d'hyperparam√®tres (optionnel)\n",
    "    \"\"\"\n",
    "    default_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 31,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_samples': 20,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    # is_unbalance pour g√©rer le d√©s√©quilibre\n",
    "    default_params['is_unbalance'] = True\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', lgb.LGBMClassifier(**default_params))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def create_mlp_pipeline(params=None):\n",
    "    \"\"\"\n",
    "    Pipeline MLP (Multi-Layer Perceptron) avec preprocessing\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionnaire d'hyperparam√®tres (optionnel)\n",
    "    \"\"\"\n",
    "    default_params = {\n",
    "        'hidden_layer_sizes': (100, 50),\n",
    "        'activation': 'relu',\n",
    "        'solver': 'adam',\n",
    "        'alpha': 0.0001,\n",
    "        'learning_rate_init': 0.001,\n",
    "        'max_iter': 200,\n",
    "        'early_stopping': True,\n",
    "        'validation_fraction': 0.1,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),  # RobustScaler pour MLP (plus robuste aux outliers)\n",
    "        ('classifier', MLPClassifier(**default_params))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonctions de cr√©ation de pipelines d√©finies:\")\n",
    "print(\"   - create_xgboost_pipeline()\")\n",
    "print(\"   - create_lightgbm_pipeline()\")\n",
    "print(\"   - create_mlp_pipeline()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7cb4a",
   "metadata": {},
   "source": [
    "## üéØ Fonction d'Optimisation Optuna\n",
    "\n",
    "Cette fonction sera utilis√©e comme objectif pour Optuna.\n",
    "Elle effectue une validation crois√©e et retourne la m√©trique √† optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4053a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction objectif Optuna d√©finie\n"
     ]
    }
   ],
   "source": [
    "def optuna_objective(trial, model_type='xgboost', metric='roc_auc'):\n",
    "    \"\"\"\n",
    "    Fonction objectif pour Optuna\n",
    "    \n",
    "    Args:\n",
    "        trial: Trial Optuna\n",
    "        model_type: 'xgboost', 'lightgbm' or 'mlp'\n",
    "        metric: M√©trique √† optimiser ('roc_auc', 'f1', 'business_cost', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Score moyen de validation crois√©e\n",
    "    \"\"\"\n",
    "    \n",
    "    # === HYPERPARAM√àTRES √Ä OPTIMISER ===\n",
    "    \n",
    "    if model_type == 'xgboost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        }\n",
    "        pipeline = create_xgboost_pipeline(params)\n",
    "        \n",
    "    elif model_type == 'lightgbm':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        }\n",
    "        pipeline = create_lightgbm_pipeline(params)\n",
    "        \n",
    "    elif model_type == 'mlp':\n",
    "        # Configurer les couches cach√©es\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "        hidden_layers = []\n",
    "        for i in range(n_layers):\n",
    "            hidden_layers.append(\n",
    "                trial.suggest_int(f'n_units_l{i}', 50, 200, step=50)\n",
    "            )\n",
    "        \n",
    "        params = {\n",
    "            'hidden_layer_sizes': tuple(hidden_layers),\n",
    "            'activation': trial.suggest_categorical('activation', ['relu', 'tanh']),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-1, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "            'max_iter': 300,  # Augment√© pour MLP\n",
    "        }\n",
    "        pipeline = create_mlp_pipeline(params)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "    \n",
    "    # === VALIDATION CROIS√âE ===\n",
    "    try:\n",
    "        cv_results = cross_validate(\n",
    "            pipeline, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            cv=skf, \n",
    "            scoring=scoring,\n",
    "            n_jobs=1,  # Important pour √©viter les conflits avec Optuna\n",
    "            return_train_score=False,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        # Retourner la m√©trique moyenne\n",
    "        mean_score = np.mean(cv_results[f'test_{metric}'])\n",
    "        \n",
    "        # Pour business_cost, on veut minimiser (valeurs n√©gatives)\n",
    "        # Optuna maximise par d√©faut, donc on retourne tel quel\n",
    "        return mean_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur dans le trial: {e}\")\n",
    "        # Retourner une tr√®s mauvaise valeur en cas d'erreur\n",
    "        return -np.inf if metric == 'business_cost' else 0.0\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction objectif Optuna d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e27750",
   "metadata": {},
   "source": [
    "## üî¨ Optimisation avec Optuna + MLflow\n",
    "\n",
    "Fonction pour lancer l'optimisation d'un mod√®le avec tracking MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4054cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction optimize_model() d√©finie\n"
     ]
    }
   ],
   "source": [
    "def optimize_model(model_type, n_trials=50, metric='roc_auc', timeout=None):\n",
    "    \"\"\"\n",
    "    Optimise un mod√®le avec Optuna et track dans MLflow\n",
    "    \n",
    "    Args:\n",
    "        model_type: 'xgboost', 'lightgbm' or 'mlp'\n",
    "        n_trials: Nombre de trials Optuna\n",
    "        metric: M√©trique √† optimiser\n",
    "        timeout: Timeout en secondes (optionnel)\n",
    "    \n",
    "    Returns:\n",
    "        best_params: Meilleurs hyperparam√®tres\n",
    "        best_value: Meilleure valeur de la m√©trique\n",
    "        study: Objet Study Optuna\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéØ OPTIMISATION: {model_type.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"M√©trique: {metric}\")\n",
    "    print(f\"Trials: {n_trials}\")\n",
    "    print(f\"CV: {N_SPLITS} folds\")\n",
    "    \n",
    "    # Cr√©er une √©tude Optuna\n",
    "    study_name = f\"{model_type}_{metric}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    # Direction: maximize pour roc_auc, f1, recall\n",
    "    # Pour business_cost (valeurs n√©gatives), on veut maximiser (moins n√©gatif = meilleur)\n",
    "    direction = 'maximize'\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=direction,\n",
    "        sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    "    )\n",
    "    \n",
    "    # Callback MLflow pour logger chaque trial\n",
    "    mlflow_callback = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=metric,\n",
    "        create_experiment=False,\n",
    "        mlflow_kwargs={\n",
    "            \"experiment_id\": mlflow.get_experiment_by_name(\"Advanced Models - Optuna Optimization\").experiment_id,\n",
    "            \"nested\": True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Lancer l'optimisation avec parent run MLflow\n",
    "    with mlflow.start_run(run_name=f\"{model_type.upper()} - Optuna {n_trials} trials\"):\n",
    "        \n",
    "        # Tags pour organisation\n",
    "        mlflow.set_tags({\n",
    "            \"author\": \"Data Science Team\",\n",
    "            \"project\": \"Home Credit Default Risk\",\n",
    "            \"phase\": \"optimization\",\n",
    "            \"model_type\": model_type,\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"framework\": model_type if model_type != 'mlp' else 'sklearn',\n",
    "            \"environment\": \"development\"\n",
    "        })\n",
    "        \n",
    "        mlflow.set_tag(\"mlflow.note.content\", f\"\"\"\n",
    "üéØ OPTIMISATION HYPERPARAM√àTRES - {model_type.upper()}\n",
    "\n",
    "üìä Configuration:\n",
    "- Optimiseur: Optuna (TPE Sampler)\n",
    "- Nombre de trials: {n_trials}\n",
    "- M√©trique objectif: {metric}\n",
    "- Validation: StratifiedKFold ({N_SPLITS} folds)\n",
    "- √âchantillons: {len(X_train):,}\n",
    "\n",
    "üí∞ M√©trique m√©tier:\n",
    "- FN co√ªte 10x plus que FP\n",
    "- Objectif: minimiser le co√ªt total\n",
    "\n",
    "üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "        \"\"\")\n",
    "        \n",
    "        # Logger les param√®tres de configuration\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        mlflow.log_param(\"n_trials\", n_trials)\n",
    "        mlflow.log_param(\"metric\", metric)\n",
    "        mlflow.log_param(\"cv_folds\", N_SPLITS)\n",
    "        mlflow.log_param(\"n_samples\", len(X_train))\n",
    "        mlflow.log_param(\"n_features\", X_train.shape[1])\n",
    "        \n",
    "        # Optimiser\n",
    "        objective_fn = lambda trial: optuna_objective(trial, model_type, metric)\n",
    "        \n",
    "        study.optimize(\n",
    "            objective_fn,\n",
    "            n_trials=n_trials,\n",
    "            timeout=timeout,\n",
    "            callbacks=[mlflow_callback],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # R√©sultats\n",
    "        best_params = study.best_params\n",
    "        best_value = study.best_value\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"‚úÖ OPTIMISATION TERMIN√âE\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Meilleur {metric}: {best_value:.4f}\")\n",
    "        print(f\"\\nMeilleurs hyperparam√®tres:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"   {param:25s}: {value}\")\n",
    "        \n",
    "        # Logger les meilleurs r√©sultats\n",
    "        mlflow.log_metric(f\"best_{metric}\", best_value)\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(f\"best_{param}\", value)\n",
    "        \n",
    "        # Entra√Æner le mod√®le final avec les meilleurs param√®tres\n",
    "        print(f\"\\nüì¶ Entra√Ænement du mod√®le final avec les meilleurs param√®tres...\")\n",
    "        \n",
    "        if model_type == 'xgboost':\n",
    "            best_pipeline = create_xgboost_pipeline(best_params)\n",
    "        elif model_type == 'lightgbm':\n",
    "            best_pipeline = create_lightgbm_pipeline(best_params)\n",
    "        elif model_type == 'mlp':\n",
    "            best_pipeline = create_mlp_pipeline(best_params)\n",
    "        \n",
    "        # Validation crois√©e finale\n",
    "        final_cv = cross_validate(\n",
    "            best_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=skf,\n",
    "            scoring=scoring,\n",
    "            n_jobs=1,\n",
    "            return_train_score=False\n",
    "        )\n",
    "        \n",
    "        # Logger toutes les m√©triques finales\n",
    "        for metric_name in scoring.keys():\n",
    "            scores = final_cv[f'test_{metric_name}']\n",
    "            mean_val = np.mean(scores)\n",
    "            std_val = np.std(scores)\n",
    "            \n",
    "            mlflow.log_metric(f\"{metric_name}_mean\", mean_val)\n",
    "            mlflow.log_metric(f\"{metric_name}_std\", std_val)\n",
    "            \n",
    "            print(f\"   {metric_name:20s}: {mean_val:.4f} (¬±{std_val:.4f})\")\n",
    "        \n",
    "        # Entra√Æner sur toutes les donn√©es\n",
    "        best_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Sauvegarder le mod√®le\n",
    "        signature = mlflow.models.signature.infer_signature(\n",
    "            X_train, \n",
    "            best_pipeline.predict_proba(X_train)[:, 1]\n",
    "        )\n",
    "        input_example = X_train.head(3)\n",
    "        \n",
    "        if model_type in ['xgboost', 'lightgbm']:\n",
    "            # Sauvegarder avec le logger sp√©cifique\n",
    "            if model_type == 'xgboost':\n",
    "                mlflow.xgboost.log_model(\n",
    "                    best_pipeline.named_steps['classifier'],\n",
    "                    \"model\",\n",
    "                    signature=signature,\n",
    "                    input_example=best_pipeline.named_steps['scaler'].transform(input_example)\n",
    "                )\n",
    "            else:\n",
    "                mlflow.lightgbm.log_model(\n",
    "                    best_pipeline.named_steps['classifier'],\n",
    "                    \"model\",\n",
    "                    signature=signature,\n",
    "                    input_example=best_pipeline.named_steps['scaler'].transform(input_example)\n",
    "                )\n",
    "        else:\n",
    "            # MLP via sklearn\n",
    "            mlflow.sklearn.log_model(\n",
    "                best_pipeline,\n",
    "                \"model\",\n",
    "                signature=signature,\n",
    "                input_example=input_example\n",
    "            )\n",
    "        \n",
    "        # Sauvegarder l'√©tude Optuna\n",
    "        import joblib\n",
    "        study_path = f\"optuna_study_{model_type}.pkl\"\n",
    "        joblib.dump(study, study_path)\n",
    "        mlflow.log_artifact(study_path)\n",
    "        os.remove(study_path)\n",
    "        \n",
    "        print(f\"‚úÖ Mod√®le et √©tude sauvegard√©s dans MLflow\")\n",
    "    \n",
    "    return best_params, best_value, study\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction optimize_model() d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fff151",
   "metadata": {},
   "source": [
    "## üöÄ Lancement des Optimisations\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:** Ajustez `n_trials` selon vos ressources :\n",
    "- **Rapide** : 20-30 trials (~5-10 min par mod√®le)\n",
    "- **Normal** : 50-100 trials (~15-30 min par mod√®le)\n",
    "- **Complet** : 100-200 trials (~30-60 min par mod√®le)\n",
    "\n",
    "Vous pouvez aussi utiliser `timeout` (en secondes) pour limiter le temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48180d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Configuration:\n",
      "   Trials par mod√®le: 30\n",
      "   M√©trique: roc_auc\n",
      "   Temps estim√©: 1-2 min par mod√®le\n"
     ]
    }
   ],
   "source": [
    "# Configuration d'optimisation\n",
    "N_TRIALS = 30  # Ajustez selon votre temps disponible\n",
    "OPTIMIZATION_METRIC = 'roc_auc'  # ou 'f1', 'recall_minority', 'business_cost'\n",
    "\n",
    "# Stocker les r√©sultats\n",
    "optimization_results = {}\n",
    "\n",
    "print(f\"üéØ Configuration:\")\n",
    "print(f\"   Trials par mod√®le: {N_TRIALS}\")\n",
    "print(f\"   M√©trique: {OPTIMIZATION_METRIC}\")\n",
    "print(f\"   Temps estim√©: {N_TRIALS * 3 // 60}-{N_TRIALS * 5 // 60} min par mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe7c1b",
   "metadata": {},
   "source": [
    "### üî∑ XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-10 16:13:23,814]\u001b[0m A new study created in memory with name: xgboost_roc_auc_20260210_161323\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ OPTIMISATION: XGBOOST\n",
      "================================================================================\n",
      "M√©trique: roc_auc\n",
      "Trials: 30\n",
      "CV: 3 folds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ee3f4a61b944d99ad478be1762cfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-10 16:17:38,418]\u001b[0m Trial 0 finished with value: 0.7657867335777139 and parameters: {'n_estimators': 150, 'max_depth': 10, 'learning_rate': 0.1205712628744377, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'min_child_weight': 2, 'gamma': 0.2904180608409973, 'reg_alpha': 8.661761457749352, 'reg_lambda': 6.011150117432088}. Best is trial 0 with value: 0.7657867335777139.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:19:33,289]\u001b[0m Trial 1 finished with value: 0.7820952300419332 and parameters: {'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.2708160864249968, 'subsample': 0.9329770563201687, 'colsample_bytree': 0.6849356442713105, 'min_child_weight': 2, 'gamma': 0.9170225492671691, 'reg_alpha': 3.0424224295953772, 'reg_lambda': 5.247564316322379}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:21:30,931]\u001b[0m Trial 2 finished with value: 0.7799954538984601 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.08012737503998542, 'subsample': 0.6557975442608167, 'colsample_bytree': 0.7168578594140873, 'min_child_weight': 4, 'gamma': 2.28034992108518, 'reg_alpha': 7.851759613930136, 'reg_lambda': 1.9967378215835974}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:24:57,989]\u001b[0m Trial 3 finished with value: 0.7661547488598868 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.011711509955524094, 'subsample': 0.8430179407605753, 'colsample_bytree': 0.6682096494749166, 'min_child_weight': 1, 'gamma': 4.7444276862666666, 'reg_alpha': 9.656320330745594, 'reg_lambda': 8.08397348116461}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:26:21,141]\u001b[0m Trial 4 finished with value: 0.771408241944033 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1024932221692416, 'subsample': 0.7760609974958406, 'colsample_bytree': 0.6488152939379115, 'min_child_weight': 5, 'gamma': 0.17194260557609198, 'reg_alpha': 9.093204020787821, 'reg_lambda': 2.587799816000169}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:28:39,591]\u001b[0m Trial 5 finished with value: 0.7814197487417015 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05864129169696527, 'subsample': 0.8186841117373118, 'colsample_bytree': 0.6739417822102108, 'min_child_weight': 10, 'gamma': 3.8756641168055728, 'reg_alpha': 9.394989415641891, 'reg_lambda': 8.948273504276488}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:34:58,378]\u001b[0m Trial 6 finished with value: 0.7715781740008946 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.01351182947645082, 'subsample': 0.6783931449676581, 'colsample_bytree': 0.6180909155642152, 'min_child_weight': 4, 'gamma': 1.9433864484474102, 'reg_alpha': 2.713490317738959, 'reg_lambda': 8.287375091519294}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:36:57,434]\u001b[0m Trial 7 finished with value: 0.7792551274758136 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.06333268775321842, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'min_child_weight': 1, 'gamma': 4.9344346830025865, 'reg_alpha': 7.722447692966574, 'reg_lambda': 1.987156815341724}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:38:53,514]\u001b[0m Trial 8 finished with value: 0.768358420844061 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.11069143219393454, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'min_child_weight': 1, 'gamma': 1.7923286427213632, 'reg_alpha': 1.1586905952512971, 'reg_lambda': 8.631034258755935}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n",
      "\u001b[32m[I 2026-02-10 16:41:26,797]\u001b[0m Trial 9 finished with value: 0.7579508842444912 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.012413189635294229, 'subsample': 0.7243929286862649, 'colsample_bytree': 0.7300733288106989, 'min_child_weight': 8, 'gamma': 3.1877873567760657, 'reg_alpha': 8.872127425763265, 'reg_lambda': 4.722149251619493}. Best is trial 1 with value: 0.7820952300419332.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Optimiser XGBoost\n",
    "xgb_params, xgb_score, xgb_study = optimize_model(\n",
    "    model_type='xgboost',\n",
    "    n_trials=N_TRIALS,\n",
    "    metric=OPTIMIZATION_METRIC\n",
    ")\n",
    "\n",
    "optimization_results['xgboost'] = {\n",
    "    'params': xgb_params,\n",
    "    'score': xgb_score,\n",
    "    'study': xgb_study\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68e310",
   "metadata": {},
   "source": [
    "### üî∂ LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef046880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser LightGBM\n",
    "lgb_params, lgb_score, lgb_study = optimize_model(\n",
    "    model_type='lightgbm',\n",
    "    n_trials=N_TRIALS,\n",
    "    metric=OPTIMIZATION_METRIC\n",
    ")\n",
    "\n",
    "optimization_results['lightgbm'] = {\n",
    "    'params': lgb_params,\n",
    "    'score': lgb_score,\n",
    "    'study': lgb_study\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce707de",
   "metadata": {},
   "source": [
    "### üß† MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1836da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser MLP\n",
    "mlp_params, mlp_score, mlp_study = optimize_model(\n",
    "    model_type='mlp',\n",
    "    n_trials=N_TRIALS,\n",
    "    metric=OPTIMIZATION_METRIC\n",
    ")\n",
    "\n",
    "optimization_results['mlp'] = {\n",
    "    'params': mlp_params,\n",
    "    'score': mlp_score,\n",
    "    'study': mlp_study\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5476d7a",
   "metadata": {},
   "source": [
    "## üìä Comparaison des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un tableau de comparaison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(optimization_results.keys()),\n",
    "    f'Best {OPTIMIZATION_METRIC}': [\n",
    "        results['score'] for results in optimization_results.values()\n",
    "    ]\n",
    "}).sort_values(f'Best {OPTIMIZATION_METRIC}', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìà COMPARAISON DES MOD√àLES\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üèÜ MEILLEUR MOD√àLE: {comparison_df.iloc[0]['Model'].upper()}\")\n",
    "print(f\"   {OPTIMIZATION_METRIC}: {comparison_df.iloc[0][f'Best {OPTIMIZATION_METRIC}']:.4f}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9fdbc",
   "metadata": {},
   "source": [
    "## üìà Visualisation des √âtudes Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b54d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice\n",
    ")\n",
    "\n",
    "# Cr√©er les visualisations pour chaque mod√®le\n",
    "for model_name, results in optimization_results.items():\n",
    "    study = results['study']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä VISUALISATIONS: {model_name.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. Historique d'optimisation\n",
    "    fig = plot_optimization_history(study)\n",
    "    fig.update_layout(title=f\"{model_name.upper()} - Optimization History\")\n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Importance des hyperparam√®tres\n",
    "    try:\n",
    "        fig = plot_param_importances(study)\n",
    "        fig.update_layout(title=f\"{model_name.upper()} - Hyperparameter Importances\")\n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Impossible de g√©n√©rer plot_param_importances: {e}\")\n",
    "    \n",
    "    # 3. Distribution des hyperparam√®tres\n",
    "    try:\n",
    "        fig = plot_slice(study)\n",
    "        fig.update_layout(title=f\"{model_name.upper()} - Hyperparameter Slices\")\n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Impossible de g√©n√©rer plot_slice: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba04a42",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarder le Meilleur Mod√®le\n",
    "\n",
    "Entra√Æner le meilleur mod√®le sur toutes les donn√©es et le sauvegarder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier le meilleur mod√®le\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_params = optimization_results[best_model_name]['params']\n",
    "\n",
    "print(f\"üèÜ Entra√Ænement du meilleur mod√®le: {best_model_name.upper()}\")\n",
    "\n",
    "# Cr√©er le pipeline avec les meilleurs param√®tres\n",
    "if best_model_name == 'xgboost':\n",
    "    final_pipeline = create_xgboost_pipeline(best_params)\n",
    "elif best_model_name == 'lightgbm':\n",
    "    final_pipeline = create_lightgbm_pipeline(best_params)\n",
    "elif best_model_name == 'mlp':\n",
    "    final_pipeline = create_mlp_pipeline(best_params)\n",
    "\n",
    "# Entra√Æner sur toutes les donn√©es\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluer sur le train\n",
    "y_pred_proba = final_pipeline.predict_proba(X_train)[:, 1]\n",
    "y_pred = final_pipeline.predict(X_train)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_pred_proba)\n",
    "train_f1 = f1_score(y_train, y_pred)\n",
    "train_recall = recall_score(y_train, y_pred)\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le entra√Æn√©\")\n",
    "print(f\"\\nüìä Performances sur le train:\")\n",
    "print(f\"   ROC-AUC: {train_auc:.4f}\")\n",
    "print(f\"   F1-Score: {train_f1:.4f}\")\n",
    "print(f\"   Recall: {train_recall:.4f}\")\n",
    "\n",
    "# Sauvegarder localement\n",
    "import joblib\n",
    "model_filename = f'best_model_{best_model_name}.pkl'\n",
    "joblib.dump(final_pipeline, model_filename)\n",
    "print(f\"\\nüíæ Mod√®le sauvegard√©: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc595798",
   "metadata": {},
   "source": [
    "## üéØ Pr√©dictions sur le Test Set\n",
    "\n",
    "G√©n√©rer les pr√©dictions pour la soumission Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur le test\n",
    "test_pred_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Cr√©er le fichier de soumission\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test_ids,\n",
    "    'TARGET': test_pred_proba\n",
    "})\n",
    "\n",
    "submission_filename = f'submission_{best_model_name}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Pr√©dictions g√©n√©r√©es: {len(submission)} lignes\")\n",
    "print(f\"üíæ Fichier cr√©√©: {submission_filename}\")\n",
    "print(f\"\\nüìä Statistiques des pr√©dictions:\")\n",
    "print(submission['TARGET'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29103b7",
   "metadata": {},
   "source": [
    "## üìã R√©sum√© Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ OPTIMISATION TERMIN√âE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"üéØ Configuration:\")\n",
    "print(f\"   M√©trique d'optimisation: {OPTIMIZATION_METRIC}\")\n",
    "print(f\"   Trials par mod√®le: {N_TRIALS}\")\n",
    "print(f\"   Validation: {N_SPLITS}-fold StratifiedKFold\")\n",
    "print(f\"   √âchantillons train: {len(X_train):,}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüìä R√©sultats par mod√®le:\")\n",
    "for model_name, results in optimization_results.items():\n",
    "    print(f\"   {model_name:10s}: {results['score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best_model_name.upper()}\")\n",
    "print(f\"   Score: {optimization_results[best_model_name]['score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"   - Mod√®le: {model_filename}\")\n",
    "print(f\"   - Soumission: {submission_filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ MLflow:\")\n",
    "print(f\"   Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"   Exp√©rience: Advanced Models - Optuna Optimization\")\n",
    "print(f\"   Visualisez avec: mlflow ui\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc3116",
   "metadata": {},
   "source": [
    "## üìö Prochaines √âtapes\n",
    "\n",
    "### üîç Analyse Approfondie\n",
    "- Analyser les feature importances\n",
    "- √âtudier les pr√©dictions erron√©es (FP et FN)\n",
    "- Cr√©er une matrice de confusion d√©taill√©e\n",
    "\n",
    "### üéØ Am√©lioration\n",
    "- **Feature Engineering** : Cr√©er de nouvelles features cibl√©es\n",
    "- **Stacking/Blending** : Combiner les 3 mod√®les\n",
    "- **Calibration** : Calibrer les probabilit√©s pr√©dites\n",
    "- **Threshold Optimization** : Trouver le seuil optimal pour minimiser le co√ªt m√©tier\n",
    "\n",
    "### üöÄ D√©ploiement\n",
    "- Cr√©er une API FastAPI\n",
    "- Containeriser avec Docker\n",
    "- Tests de charge et monitoring\n",
    "- Validation m√©tier\n",
    "\n",
    "### üìä MLflow\n",
    "Pour visualiser toutes vos exp√©riences:\n",
    "```bash\n",
    "cd /home/zmxw1768/Documents/oc_mlops\n",
    "mlflow ui\n",
    "```\n",
    "Puis ouvrez: http://localhost:5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
